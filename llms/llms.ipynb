{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd5565b",
   "metadata": {},
   "source": [
    "## Global Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bcd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install defeatbeta-api\n",
    "!{sys.executable} -m pip install diffusers\n",
    "!{sys.executable} -m pip install huggingface-hub\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!{sys.executable} -m pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c667ee6",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "prompt = list(input(\"Enter double-hyphen-separated values for sentiment analysis:\").split(\"--\"))\n",
    "\n",
    "results = classifier(prompt)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cb2cd",
   "metadata": {},
   "source": [
    "## Text-to-Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    torch_dtype=dtype\n",
    ")\n",
    "\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "# Memory optimizations (VERY important)\n",
    "pipe.enable_attention_slicing()\n",
    "pipe.vae.enable_slicing()\n",
    "\n",
    "generator = torch.Generator(device).manual_seed(0)\n",
    "\n",
    "prompt = input(\"Input something to generate an image\")\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=40,  # 50 is overkill for FLUX\n",
    "    max_sequence_length=512,\n",
    "    generator=generator\n",
    ").images[0]\n",
    "\n",
    "image.save(\"flux-dev.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1821cd",
   "metadata": {},
   "source": [
    "## Clustering & Semantic Search Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"To be, or not to be; that is the question.\", \n",
    "             \"Whether 'tis nobler in the mind to suffer the slings and arrows of outrageous fortune, or to take arms against a sea of troubles, and by opposing end them\"]\n",
    "\n",
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenization\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings)\n",
    "\n",
    "print(f\"Sentence embeddings:\\n{sentence_embeddings}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c18356",
   "metadata": {},
   "source": [
    "## Financial News Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\"The Fed has declared a 0.2% increase in interest rates\", \"TSLA's stock price has sky-rocketed in the last 24 hours.\"]\n",
    "\n",
    "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output = model(**tokens)\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(**tokens)\n",
    "\n",
    "logits = output.logits\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "predicted_class_ids = torch.argmax(probs, dim=-1).tolist()\n",
    "predicted_labels =  [model.config.id2label[i] for i in predicted_class_ids]\n",
    "\n",
    "for s, l, p, c in zip(sequences, predicted_labels, probs, predicted_class_ids):\n",
    "    print(f\"The statement '{s}' is classified as having {l} sentiment at a {p[c]:.4f} probability\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
